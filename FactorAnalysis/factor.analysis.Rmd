---
title: "Reliability and factor analysis of isiZulu translations of the CDRISC and Resilience Scale"
author: 'Peter Kamerman' 
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  md_document:
    variant: markdown_github
---

## Load required packages and set chunk options
```{r miscellaneous.1, include = FALSE}
# Load libraries
library(pander)
library(readr)
library(knitr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(psych)
library(GPArotation) # for fa function in 'psych'

# Set seed
set.seed(123)

# Set knitr chunk options
opts_chunk$set(echo = FALSE,
               warning = FALSE,
               message = FALSE,
               fig.path = './figures/',
               dev = c('png', 'pdf'),
               cache.extra = rand_seed,
               tidy = TRUE, 
               tidy.opts = list(width.cutoff = 65))
```

## CD-RISC
### Item coding
```{r code.key.1}
# Make a vector of CD-RISC questions
cdr.names <- c('Q1 I am able to adapt when changes occur', 'Q2 I have at least one close and secure relationship that helps me when I\'m stressed', 'Q3 When there are no clear solutions to my problems, sometimes fate or God can help', 'Q4 I can deal with whatever comes my way', 'Q5 Past successes give me confidence in dealing with new challenges and difficulties', 'Q6 I try and see the humorous side of things when I\'m faced with problems', 'Q7 Having to cope with stress can make me stronger', 'Q8 I tend to bounce back after illness, injury or other hardships', 'Q9 Good or bad, I believe that most things happen for a reason', 'Q10 I give my best effort no matter what the outcome may be', 'Q11 I believe I can achieve my goals, even if there are obstacles', 'Q12 Even when things look hopeless, I don\'t give up', 'Q13 During times of stress/crisis, I know where to turn for help', 'Q14 Under pressure, I stay focused and think clearly', 'Q15 I prefer to take the lead in solving problems rather than letting others make all the decisions', 'Q16 I am not easily discouraged by failure', 'Q17 I think of myself as a strong person when dealing with life\'s challenges and difficulties', 'Q18 I can make unpopular or difficult decisions that affect other people, if it is necessary', 'Q19 I am able to handle unpleasant or painful feelings like sadness, fear, and anger', 'Q20 In dealing with life\'s problems, sometimes you have to act on a hunch without knowing why', 'Q21 I have a strong sense of purpose in life', 'Q22 I feel in control of my life', 'Q23 I like challenges', 'Q24 I work to attain my goals no matter what roadblocks I encounter along the way', 'Q25 I take pride in my achievements')

# Make a data.frame with 'Label' and 'Key' columns
cdr.key <- data.frame(Label = c(paste('Q', seq(1:25), sep = '')), 
                      Key = gsub('Q.|Q.. ', '', cdr.names))

# Tablulate
pander(cdr.key, style = 'rmarkdown', 
       justify = 'left', 
       split.table = 'inf')
```

### Import data
```{r import.1, echo = TRUE}
# Read csv
data.1 <- read_csv('./data/cd.risc.csv')
```

### Inspect
```{r inspect.1}
# Inspect the data
head(data.1)
tail(data.1)
str(data.1)
```

### Clean
```{r clean.1, echo = TRUE}
# Convert ID to factor
data.1$ID <- factor(data.1$ID) 
```

### Internal consistency
_**Use polychoric correlation matrix because data are ordinal integers, and therefore Pearson's correlation matrix does not apply**_
```{r ic.1}
# Remove ID column
data.1.1 <- data.1[,-1]

# Get a summary of the data
kable(describe(data.1.1))

# Generate and view polychoric correlation matrix
pc.1 <- polychoric(data.1.1)

# Generate internal consistency coefficient alpha
pander(summary(alpha(pc.1$rho)), 
       style='rmarkdown', 
       justify='left', 
       round = 2, 
       caption='CD-RISC: internal consistency')
```

### Factor analysis - initial
_**Use polychoric correlation matrix because data are ordinal integers, and therefore Pearson's correlation matrix does not apply**_
```{r fa.1}
# Print parallel plots to estimate factor solution
fa.parallel(data.1.1, 
            fm='ml', 
            cor='poly')

# Complete factor analysis - use maximum liklihood (ml) method
## Use nfactor = 3 based on fa.parallel plot
## Thereafter repeat analysis using 2 and 4 factors
## Test oblique rotation (Oblimin), assuming correlation between factors

### Oblimin: 3 factor
fa.1f3o <- fa.poly(data.1.1, 
                   nfactors = 3, 
                   rotate='oblimin', 
                   fm='ml', 
                   global = F)
### Oblimin: 4 factor
fa.1f4o <- fa.poly(data.1.1, 
                   nfactors = 4, 
                   rotate='oblimin', 
                   fm='ml', 
                   global = F)
### Oblimin: 2 factor
fa.1f2o <- fa.poly(data.1.1, 
                   nfactors = 2, 
                   rotate='oblimin', 
                   fm='ml', 
                   global = F)

# Interpret
## Oblimin: 3 factor (suggested)
fa.diagram(fa.1f3o, 
           cut = 0, 
           digits = 3, 
           labels = as.list(cdr.names))
print(fa.1f3o, 
      cut = 0, 
      digits = 3)
## Oblimin: 4 factor
fa.diagram(fa.1f4o, 
           cut = 0, 
           digits = 3, 
           labels = as.list(cdr.names))
print(fa.1f4o, 
      cut = 0, 
      digits = 3)
## Oblimin: 2 factor 
fa.diagram(fa.1f2o, 
           cut = 0, 
           digits = 3, 
           labels = as.list(cdr.names))
print(fa.1f2o, 
      cut = 0, 
      digits = 3)
```

### Outcome of initial factor analysis
The 3-factor structure produced the most parsimonious outcome. One item (Q2: 'I have at least one close and secure relationship that helps me when I'm stressed') had factor loading < 0.3, and was removed and the data reanalysed with a 3-factor structure.

### Factor analysis - secondary 
*Item Q2 removed**  
```{r fa.1b}
# Remove Q2
data.1.1b <- data.1.1[, -c(2)]

# Generate and view polychoric correlation matrix
pc.1b <- polychoric(data.1.1b)

# Generate internal consistency coefficient alpha
pander(summary(alpha(pc.1b$rho)), 
       style='pandoc', 
       justify='left', 
       round = 2, 
       caption='CD-RISC: internal consistency after removal of Q2')

# Print parallel plots to estimate factor solution
fa.parallel(data.1.1b, 
            fm='ml', 
            cor='poly')

# Complete factor analysis - use maximum liklihood (ml) method
## Use nfactor = 3 based on fa.parallel plot

### Oblimin: 3 factor
fa.1bf3o <- fa.poly(data.1.1b, 
                    nfactors = 3, 
                    rotate='oblimin', 
                    fm='ml', 
                    global = F)

# Interpret
## Oblimin: 3 factor
fa.diagram(fa.1bf3o, 
           cut = 0, 
           digits = 3)
print(fa.1bf3o, 
      cut = 0, 
      digits = 3)
```

## Resilience Scale
### Item coding
```{r code.key.2}
rs.names <- c('Q1 When I make plans, I follow through with them', 'Q2 I usually manage one way or another', 'Q3 I am able to depend on myself more than anyone else', 'Q4 Keeping interested in things is important to me', 'Q5 I can be on my own if I have to', 'Q6 I feel proud that I have accomplished things in life', 'Q7 I usually take things in my stride', 'Q8 I am friends with myself', 'Q9 I feel that I can handle many things at a time', 'Q10 I am determined', 'Q11 I seldom wonder what the point of it all is', 'Q12 I take things one day at a time', 'Q13 I can get through difficult times because I have experienced difficulty before', 'Q14 I have self-discipline', 'Q15 I keep interested in things', 'Q16 I can usually find something to laugh about', 'Q17 My belief in myself gets me through hard times', 'Q18 In an emergency, I am someone people can general rely on', 'Q19 I can usually look at a situation in a number of ways', 'Q20 Sometimes I make myself do things whether I want to or not', 'Q21 My life has meaning', 'Q22 I do not dwell on things I cannot do anything about', 'Q23 When I am in a difficult situation, I can usually find my way out of it', 'Q24 I have enough energy to do what I have to do', 'Q25 It is OK if there are people who do not like me')

rs.key <- data.frame(Label = c(paste('Q', seq(1:25), sep='')), 
                     Key = gsub('Q.|Q.. ', '', rs.names))

# Tablulate
pander(rs.key, 
       style = 'rmarkdown', 
       split.table = 'inf', 
       justify = 'left')
```

### Import data
```{r import.2, echo = TRUE}
# Read csv
data.2 <- read_csv('./data/resilience.scale.csv')
```

### Inspect 
```{r inspect.2}
# Inspect the data
head(data.2)
tail(data.2)
str(data.2)
```

### Clean
```{r clean.2, echo = TRUE}
# Convert ID to factor
data.2$ID <- factor(data.2$ID) 
```

### Internal consistency
**Use polychoric correlation matrix because data are ordinal integers, and therefore Pearson's correlation matrix does not apply**
```{r ic.2}
# Remove ID column
data.2.1 <- data.2[,-1]

# Look at the data
kable(describe(data.2.1))

# Generate and view polychoric correlation matrix
pc.2 <- polychoric(data.2.1)

# Generate internal consistency coefficient alpha
pander(summary(alpha(pc.2$rho)), 
       style='rmarkdown', 
       justify='left', 
       round = 2, 
       caption='CD-RISC: internal consistency')
```

### Factor analysis
**Use polychoric correlation matrix because data are ordinal integers, and therefore Pearson's correlation matrix does not apply**
```{r fa.2}
# Print parallel plots to estimate factor solution
fa.parallel(data.2.1, 
            fm='ml', 
            cor='poly')

# Complete factor analysis - use maximum liklihood (ml) method
## Start with nfactor = 1 based on fa.parallel plot
## Thereafter repeat analysis using 2 factors
## Test oblique rotation first (Oblimin)

### Oblimin: 1 factor
fa.2f1o <- fa.poly(data.2.1, 
                   nfactors = 1, 
                   rotate='oblimin', 
                   fm='ml', 
                   global = F)
### Oblimin: 2 factor
fa.2f2o <- fa.poly(data.2.1, 
                   nfactors = 2, 
                   rotate='oblimin', 
                   fm='ml', 
                   global = F)

# Interpret
## Oblimin: 1 factor
fa.diagram(fa.2f1o, cut = 0, digits = 3, labels = as.list(rs.names))
print(fa.2f1o, cut = 0, digits = 3)
## Oblimin: 2 factor
fa.diagram(fa.2f2o, cut = 0, digits = 3, labels = as.list(rs.names))
print(fa.2f2o, cut = 0, digits = 3)
```

### Outcome of initial factor analysis
The 2-factor structure produced the most parsimonious outcome based on the empirical $\chi$^2^ goodness of fit test, but the 1-factor solution was recommended by the parallel plot. On the 1-factor solution, two items (Q11: 'I seldom wonder what the point of it all is', and Q20: 'Sometimes I make myself do things whether I want to or not') had factor loadings < 0.3, and were removed and the data reanalysed with a 1-factor structure (as per the original and revised parallel plots), and a 2-factor structure (based on the empirical $\chi$^2^ goodness of fit test on the original 2-factor solution). On the 2-factor solution, only one item (Q11: 'I seldom wonder what the point of it all is') had factor loadings < 0.3, and was removed and the data reanalysed with a 1-factor structure (as per the original and revised parallel plots), and a 2-factor structure (based on the empirical $\chi$^2^ goodness of fit test on the original 2-factor solution).

### Factor analysis - secondary 
*Item Q11 and Q20 removed based on the outcome of the original 1-factor solution**  
```{r fa.2b1}
# Remove items Q11 and Q20
data.2.1b1 <- data.2.1[, -c(11,20)]

# Generate and view polychoric correlation matrix
pc.2b1 <- polychoric(data.2.1b1)

# Generate internal consistency coefficient alpha
pander(summary(alpha(pc.2b1$rho)), style='rmarkdown', justify='left', round = 2, caption='CD-RISC: internal consistency after removal fo Q11 and Q20')

# Print parallel plots
fa.parallel(data.2.1b1, fm='ml', cor='poly')

# Complete factor analysis - use maximum liklihood (ml) method
## Start with nfactor = 1 based on fa.parallel plot

### Oblimin: 1 factor
fa.2b1f1o <- fa.poly(data.2.1b1, nfactors = 1, rotate='oblimin', fm='ml', global = F)
### Oblimin: 2 factor
fa.2b1f2o <- fa.poly(data.2.1b1, nfactors = 2, rotate='oblimin', fm='ml', global = F)

# Interpret
## Oblimin: 1 factor
fa.diagram(fa.2b1f1o, cut = 0, digits = 3)
print(fa.2b1f1o, cut = 0, digits = 3)
## Oblimin: 2 factor
fa.diagram(fa.2b1f2o, cut = 0, digits = 3)
print(fa.2b1f2o, cut = 0, digits = 3)
```

*Only item Q11 removed based on the outcome of the original 2-factor solution**  
```{r fa.2b2}
# Remove items Q11 and Q20
data.2.1b2 <- data.2.1[, -c(11)]

# Print parallel plots to estimate factor solution
fa.parallel(data.2.1b2, 
            fm='ml', 
            cor='poly')

# Complete factor analysis - use maximum liklihood (ml) method
## Start with nfactor = 3 based on fa.parallel plot
## Thereafter repeat analysis using 2 and 4 factors
## Test oblique rotation first (Oblimin)
### Oblimin: 1 factor
fa.2b2f1o <- fa.poly(data.2.1b2, nfactors = 1, rotate='oblimin', fm='ml', global = F)
### Oblimin: 2 factor
fa.2b2f2o <- fa.poly(data.2.1b2, nfactors = 2, rotate='oblimin', fm='ml', global = F)

# Interpret
## Oblimin: 1 factor
fa.diagram(fa.2b2f1o, cut = 0, digits = 3)
print(fa.2b2f1o, cut = 0, digits = 3)
## Oblimin: 2 factor
fa.diagram(fa.2b2f2o, cut = 0, digits = 3)
print(fa.2b2f2o, cut = 0, digits = 3)
```

## Session information
```{r SessionInfo}
sessionInfo()
```




